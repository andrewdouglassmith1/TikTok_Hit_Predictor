{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spoken-intersection",
   "metadata": {},
   "source": [
    "# Notebook Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-neighborhood",
   "metadata": {},
   "source": [
    "In this notebook I optimize a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stone-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "furnished-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-health",
   "metadata": {},
   "source": [
    "# Pickle in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "apparent-seven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>TikTok Link</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Position Change</th>\n",
       "      <th>spotify_uri</th>\n",
       "      <th>audio_analysis</th>\n",
       "      <th>feature_analysis</th>\n",
       "      <th>success</th>\n",
       "      <th>year</th>\n",
       "      <th>top_albums</th>\n",
       "      <th>top_artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.tiktok.com/music/All-TikTok-Mashup...</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5TpvLkESnw1g9wDz52efeO</td>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.88, 'energy': 0.501, 'key':...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.tiktok.com/music/WAP-Megan-Thee-St...</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4Oun2ylbjFKMPTiaSbbCih</td>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.935, 'energy': 0.454, 'key'...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Cardi B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0        0         0.880   0.501  2.0    -6.774   1.0        0.062   \n",
       "1      162         0.935   0.454  1.0    -7.509   1.0        0.375   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  ...  \\\n",
       "0        0.0494            0.0695    0.4360  ...   \n",
       "1        0.0194            0.0000    0.0824  ...   \n",
       "\n",
       "                                         TikTok Link  Release Date  \\\n",
       "0  https://www.tiktok.com/music/All-TikTok-Mashup...    2020-08-17   \n",
       "1  https://www.tiktok.com/music/WAP-Megan-Thee-St...    2018-03-22   \n",
       "\n",
       "  Position Change             spotify_uri  \\\n",
       "0            23.0  5TpvLkESnw1g9wDz52efeO   \n",
       "1            15.0  4Oun2ylbjFKMPTiaSbbCih   \n",
       "\n",
       "                                      audio_analysis  \\\n",
       "0  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "1  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "\n",
       "                                    feature_analysis success    year  \\\n",
       "0  {'danceability': 0.88, 'energy': 0.501, 'key':...       1  2020.0   \n",
       "1  {'danceability': 0.935, 'energy': 0.454, 'key'...       1  2018.0   \n",
       "\n",
       "   top_albums top_artists  \n",
       "0       Other       Other  \n",
       "1       Other     Cardi B  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle in cleaned dataframe\n",
    "\n",
    "# Designate path\n",
    "\n",
    "path = r\"C:\\Users\\Andrew\\Documents\\Metis\\TikTok_Song_Predictor\\Pickle\\df_agg.pkl\"\n",
    "\n",
    "df = pickle.load(open(path,'rb'))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-russia",
   "metadata": {},
   "source": [
    "# CV KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "noticed-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features from label\n",
    "\n",
    "X = df.loc[:,['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','year']]\n",
    "\n",
    "y = df['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "average-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 3: 60% train, 20% validation, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "preliminary-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# Oversample training data\n",
    "X_adasyn_tr, y_adasyn_tr = ada.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "transparent-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_adasyn_tr = scaler.fit_transform(X_adasyn_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adequate-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "k_range = list(range(1, 31))\n",
    "weight_options = ['uniform', 'distance']\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "increased-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "confused-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "suspended-luther",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03697374, 0.0260958 , 0.0268012 , 0.02508183, 0.0245018 ,\n",
       "        0.02511075, 0.02364514, 0.02460833, 0.02400606, 0.02503729]),\n",
       " 'std_fit_time': array([0.01212002, 0.00277676, 0.00208139, 0.00150602, 0.0007656 ,\n",
       "        0.00125184, 0.00166795, 0.00130978, 0.00165578, 0.00147555]),\n",
       " 'mean_score_time': array([0.15117085, 0.12352729, 0.22245226, 0.2016248 , 0.14172611,\n",
       "        0.22600586, 0.17039297, 0.22586064, 0.15679355, 0.20288796]),\n",
       " 'std_score_time': array([0.0571168 , 0.01560528, 0.00494172, 0.00792378, 0.00296366,\n",
       "        0.00793487, 0.0040042 , 0.01486671, 0.00453339, 0.0070317 ]),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'distance', 'uniform', 'distance', 'uniform',\n",
       "                    'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 3, 19, 23, 7, 28, 17, 25, 7, 29],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'weights': 'uniform', 'n_neighbors': 1},\n",
       "  {'weights': 'distance', 'n_neighbors': 3},\n",
       "  {'weights': 'uniform', 'n_neighbors': 19},\n",
       "  {'weights': 'distance', 'n_neighbors': 23},\n",
       "  {'weights': 'distance', 'n_neighbors': 7},\n",
       "  {'weights': 'uniform', 'n_neighbors': 28},\n",
       "  {'weights': 'distance', 'n_neighbors': 17},\n",
       "  {'weights': 'uniform', 'n_neighbors': 25},\n",
       "  {'weights': 'uniform', 'n_neighbors': 7},\n",
       "  {'weights': 'distance', 'n_neighbors': 29}],\n",
       " 'split0_test_score': array([0.89259259, 0.84907407, 0.775     , 0.79722222, 0.82592593,\n",
       "        0.76018519, 0.80092593, 0.76759259, 0.81481481, 0.78796296]),\n",
       " 'split1_test_score': array([0.89434662, 0.8489342 , 0.78405931, 0.79332715, 0.82391103,\n",
       "        0.77015755, 0.80444856, 0.77293791, 0.80630213, 0.78035218]),\n",
       " 'split2_test_score': array([0.8776645 , 0.85078777, 0.78591288, 0.79888786, 0.82669138,\n",
       "        0.78313253, 0.79981464, 0.78220575, 0.8137164 , 0.79518072]),\n",
       " 'split3_test_score': array([0.86932345, 0.83595922, 0.77386469, 0.78776645, 0.8257646 ,\n",
       "        0.77757183, 0.80074143, 0.77108434, 0.81186284, 0.78591288]),\n",
       " 'split4_test_score': array([0.87117702, 0.84430028, 0.79147359, 0.80352178, 0.82854495,\n",
       "        0.7905468 , 0.80722892, 0.78962002, 0.82113068, 0.79610751]),\n",
       " 'split5_test_score': array([0.87395737, 0.84986098, 0.82020389, 0.82298424, 0.84059314,\n",
       "        0.81278962, 0.82947173, 0.81278962, 0.82947173, 0.81835032]),\n",
       " 'split6_test_score': array([0.86932345, 0.84522706, 0.77386469, 0.7905468 , 0.8081557 ,\n",
       "        0.77571826, 0.79425394, 0.76830399, 0.79518072, 0.78313253]),\n",
       " 'split7_test_score': array([0.86839666, 0.84615385, 0.78127896, 0.78683967, 0.82113068,\n",
       "        0.7673772 , 0.802595  , 0.77108434, 0.80630213, 0.7849861 ]),\n",
       " 'split8_test_score': array([0.89156627, 0.86005561, 0.78313253, 0.78591288, 0.83873957,\n",
       "        0.77201112, 0.80074143, 0.77293791, 0.82669138, 0.78220575]),\n",
       " 'split9_test_score': array([0.8952734 , 0.85912882, 0.80444856, 0.79981464, 0.82113068,\n",
       "        0.79888786, 0.81278962, 0.79332715, 0.81278962, 0.802595  ]),\n",
       " 'mean_test_score': array([0.88036213, 0.84894819, 0.78732391, 0.79668237, 0.82605876,\n",
       "        0.7808378 , 0.80530112, 0.78018836, 0.81382625, 0.79167859]),\n",
       " 'std_test_score': array([0.01101168, 0.00665751, 0.01404459, 0.01046322, 0.00867434,\n",
       "        0.01510903, 0.00930015, 0.01378148, 0.00964597, 0.01115942]),\n",
       " 'rank_test_score': array([ 1,  2,  8,  6,  3,  9,  5, 10,  4,  7])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=42)\n",
    "rand.fit(X_adasyn_tr, y_adasyn_tr)\n",
    "rand.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "precise-alpha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8803621322898432\n",
      "{'weights': 'uniform', 'n_neighbors': 1}\n",
      "KNeighborsClassifier(n_neighbors=1)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)\n",
    "print(rand.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-banks",
   "metadata": {},
   "source": [
    "# Applying best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "representative-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features from label\n",
    "\n",
    "X = df.loc[:,['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','year']]\n",
    "\n",
    "y = df['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "joint-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into 3: 60% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "chubby-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample\n",
    "\n",
    "ada = ADASYN(random_state=42)\n",
    "\n",
    "# Oversample training data\n",
    "X_adasyn_tr, y_adasyn_tr = ada.fit_resample(X_train,y_train)\n",
    "X_adasyn_test, y_adasyn_test = ada.fit_resample(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "square-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_adasyn_tr = scaler.fit_transform(X_adasyn_tr)\n",
    "X_adasyn_test = scaler.fit_transform(X_adasyn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "requested-horizon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the logisitc regression\n",
      "Training score:  86.31%\n",
      "Val set score:  73.48%\n",
      "\n",
      "Precision / Recall val\n",
      "Val F1 score:   0.75%\n",
      "Precision:   0.72%,   Recall:   0.78%\n"
     ]
    }
   ],
   "source": [
    "# run initial logistic regression\n",
    "# Define KNN\n",
    "model = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform')\n",
    "model.fit(X_adasyn_tr, y_adasyn_tr)\n",
    "y_predict = model.predict(X_adasyn_test)\n",
    "\n",
    "#scores\n",
    "print(\"Scores for the logisitc regression\")\n",
    "print(\"Training score: {:6.2f}%\".format(100*model.score(X_adasyn_tr, y_adasyn_tr)))\n",
    "print(\"Val set score: {:6.2f}%\".format(100*model.score(X_adasyn_test, y_adasyn_test)))\n",
    "\n",
    "#precision/recall\n",
    "print(\"\\nPrecision / Recall val\")\n",
    "print(\"Val F1 score: {:6.2f}%\".format(f1_score(model.predict(X_adasyn_test), y_adasyn_test)))\n",
    "print(\"Precision: {:6.2f}%,   Recall: {:6.2f}%\".format(precision_score(y_adasyn_test, y_predict), \n",
    "                                                     recall_score(y_adasyn_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-television",
   "metadata": {},
   "source": [
    "Our randomized search cv tests seemed to have been to wide - n_neighbors = 10, weights = 'uniform' and result in the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-accordance",
   "metadata": {},
   "source": [
    "# Pickle out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "contemporary-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle model\n",
    "path = r\"C:\\Users\\Andrew\\Documents\\Metis\\TikTok_Song_Predictor\\Pickle\\knn_model.pkl\"\n",
    "pickle.dump(model, open(path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
