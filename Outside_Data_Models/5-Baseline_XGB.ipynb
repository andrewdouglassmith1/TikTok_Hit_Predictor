{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liable-baghdad",
   "metadata": {},
   "source": [
    "# Notebook Summary\n",
    "In this notebook I test a baseline XGB Boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "significant-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-prize",
   "metadata": {},
   "source": [
    "# Pickle in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mechanical-symbol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>year</th>\n",
       "      <th>spotify_artists</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.459</td>\n",
       "      <td>120.038</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.357</td>\n",
       "      <td>133.073</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.880   0.501  2.0    -6.774   1.0        0.062        0.0494   \n",
       "1         0.935   0.454  1.0    -7.509   1.0        0.375        0.0194   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo    year  spotify_artists  \\\n",
       "0            0.0695    0.4360    0.459  120.038  2020.0                0   \n",
       "1            0.0000    0.0824    0.357  133.073  2018.0                1   \n",
       "\n",
       "   success  \n",
       "0      1.0  \n",
       "1      1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle in data\n",
    "\n",
    "path = r\"C:\\Users\\Andrew\\Documents\\Metis\\TikTok_Hit_Predictor\\Pickle\\supervised_factorized.pkl\"\n",
    "\n",
    "df = pickle.load(open(path,'rb'))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-selling",
   "metadata": {},
   "source": [
    "# XG Boost - Directly altered weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pacific-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features from label\n",
    "\n",
    "X = df.loc[:,['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','year','spotify_artists']]\n",
    "\n",
    "y = df['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validate\n",
    "#Split data into 3: 60% train, 20% validation, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-heater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 7.093\n"
     ]
    }
   ],
   "source": [
    "# calculating small_pos_weight\n",
    "# count examples in each class\n",
    "counter = Counter(y_train)\n",
    "# estimate scale_pos_weight value\n",
    "estimate = counter[0] / counter[1]\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "residential-clarity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\spark\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=30000, n_jobs=-1, num_parallel_tree=1,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=7.728,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier( \n",
    "                        n_estimators=30000,\n",
    "                        max_depth=8,\n",
    "                        objective='binary:logistic', \n",
    "                        learning_rate=.05, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=3,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight = 7.728,\n",
    "                        n_jobs = -1\n",
    "                       )\n",
    "eval_set=[(X_train,y_train),(X_val,y_val)]\n",
    "\n",
    "gbm.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='error', #new evaluation metric: classification error (could also use AUC, e.g.)\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worst-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the XGB model test data\n",
      "\n",
      "Accuracy score: 94.3322%\n",
      "F1 score: 81.1280%\n",
      "F2 score: 90.6887%\n",
      "Precision score: 69.0037%\n",
      "Recall score: 98.4211%\n",
      "AUC: 96.0878%\n"
     ]
    }
   ],
   "source": [
    "#scores\n",
    "print(\"Scores for the XGB model test data\")\n",
    "\n",
    "print(\"\\nAccuracy score: {:6.4f}%\".format(100*accuracy_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit))))\n",
    "print(\"F1 score: {:6.4f}%\".format(100*f1_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit))))\n",
    "print(\"F2 score: {:6.4f}%\".format(100*fbeta_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit),beta=2.0)))\n",
    "print(\"Precision score: {:6.4f}%\".format(100*precision_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit))))\n",
    "print(\"Recall score: {:6.4f}%\".format(100*recall_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit))))\n",
    "print(\"AUC: {:6.4f}%\".format(100*roc_auc_score(y_test, gbm.predict(X_test, ntree_limit=gbm.best_ntree_limit))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
